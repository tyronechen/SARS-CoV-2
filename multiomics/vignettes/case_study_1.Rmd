---
title: "Case study 1"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
    number_sections: true
  github_document:
    toc: true
    toc_depth: 2
    number_sections: true
  html_notebook:
    toc: true
    toc_depth: 2
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Case study 1}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r init, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r global-options, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.path='figs_1/',
                      echo=TRUE, warning=FALSE, message=FALSE)
```

Copyright (c) 2020 <a href="https://orcid.org/0000-0002-9207-0385">Tyrone Chen <img alt="ORCID logo" src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" width="16" height="16" /></a>, <a href="https://orcid.org/0000-0002-0827-866X">Melcy Philip <img alt="ORCID logo" src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" width="16" height="16" /></a>, <a href="https://orcid.org/0000-0003-3923-1116">Kim-Anh Lê Cao <img alt="ORCID logo" src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" width="16" height="16" /></a>, <a href="https://orcid.org/0000-0003-0181-6258">Sonika Tyagi <img alt="ORCID logo" src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" width="16" height="16" /></a>

Code in this package and git repository [https://gitlab.com/tyagilab/sars-cov-2/](https://gitlab.com/tyagilab/sars-cov-2/) is provided under a [MIT license](https://opensource.org/licenses/MIT). This documentation is provided under a [CC-BY-3.0 AU license](https://creativecommons.org/licenses/by/3.0/au/).

[Visit our lab website here.](https://bioinformaticslab.erc.monash.edu/) Contact Sonika Tyagi at [sonika.tyagi@monash.edu](mailto:sonika.tyagi@monash.edu).

# Index

- [Introduction](introduction.html)
- [Case study 1](case_study_1.html)
- [Case study 2](case_study_2.html)

# Running the script

Load the library.

```{r setup}
library(multiomics)
```

A script to reproduce our analysis for case study 1 is shown. [You can also download this here](https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/src/case_study_1/example.sh). This may take up to a few hours to run.

```
Rscript ../run_pipeline.R \
   ../../data/case_study_1/classes_diablo.txt  \
   --classes_secondary ../../data/case_study_1/pch.txt \
   --dropna_classes TRUE \
   --dropna_prop 0 \
   --data ../../data/case_study_1/diablo_proteome.txt ../../data/case_study_1/diablo_translatome.txt \
   --data_names proteome translatome \
   --mappings ../../data/case_study_1/proteome_mapfile.txt ../../data/case_study_1/translatome_mapfile.txt \
   --ncpus 6 \
   --diablocomp 0 \
   --diablo_keepx 5 10 12 14 16 18 20 30 \
   --icomp 24 \
   --pcomp 10 \
   --plsdacomp 4 \
   --splsdacomp 4 \
   --splsda_keepx 10 25 50 100 \
   --dist_plsda centroids.dist \
   --dist_splsda centroids.dist \
   --dist_diablo mahalanobis.dist \
   --contrib max \
   --outfile_dir ../../results/case_study_1/EXAMPLE \
   --rdata RData.RData \
   --plot Rplots.pdf \
   --args Rscript.sh
```

# Input data

## Biological context

This dataset contains two omics data: proteome and translatome. There are three biological replicates for 8 sample types. Cell cultures (uninfected/infected with SARS-CoV-2) were resampled over four timepoints. The original publication with the source data is here:

- Bojkova, D., Klann, K., Koch, B. et al. Proteomics of SARS-CoV-2-infected host cells reveals therapy targets. *Nature* **583,** 469–472 (2020). [https://doi.org/10.1038/s41586-020-2332-7](https://doi.org/10.1038/s41586-020-2332-7)

## Summary

The data used as input to this pipeline available in gitlab:

- [biological class information](https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/classes_diablo.txt)
- [longitudinal measurement information](https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/pch.txt)
- [proteome mappings](https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/proteome_mapfile.txt)
- [translatome mappings](https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/translatome_mapfile.txt)
- [proteome](https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/diablo_proteome.txt)
- [translatome](https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/diablo_translatome.txt)

## Metadata

The `classes_diablo.txt` sample information file is loaded as a vector:

```
> classes
 [1] "Control_2h"  "Control_2h"  "Control_2h"  "Control_6h"  "Control_6h"
 [6] "Control_6h"  "Control_10h" "Control_10h" "Control_10h" "Control_24h"
[11] "Control_24h" "Control_24h" "Virus_2h"    "Virus_2h"    "Virus_2h"
[16] "Virus_6h"    "Virus_6h"    "Virus_6h"    "Virus_10h"   "Virus_10h"
[21] "Virus_10h"   "Virus_24h"   "Virus_24h"   "Virus_24h"
```

The `pch.txt` repeated measurements information file is loaded as a vector:

```
> pch
 [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3
```

## Data

The proteome and translatome data have 24 matched samples and an arbitrary number of features.

# Input data

For reference, you can also access all these loaded data below and results in the `RData` object. Data objects in both this walkthrough and the `RData` object have identical names. The code blocks in this walkthrough will reproduce the same data structures. Not all values may be identical since some functions may be non-deterministic. This is true even if a seed is specified, since `R >=3.6` these are not reproducible across machines.

<details>
  <summary>Click to expand code block</summary>
  ```{r load_rdata_obj, eval=TRUE}
  url_rdata <- "https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/results/case_study_1/RData.RData"
  download.file(url_rdata, "RData.RData")
  load("RData.RData")
  ls()
  ```
  > **NOTE**: There are some differences in the R data object for case studies 1 and 2. Case study 1 was originally performed using an early version of the code. It has since been streamlined for case study 2, which contains more information. However, both analyses are reproducible and the user can if needed further investigate the internal data structures after loading them.

</details>

For case study 1, you can run the pipeline directly but it will take some time (up to a few hours to run from end to end). In this walkthrough, we use the `RData` object created as a result and load data from there directly to skip long-running steps.

Obtain the input data from the git repository.

<details>
  <summary>Click to expand code block</summary>
  ```{r get_data, eval=FALSE}
  url_class <- "https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/classes_diablo.txt"
  url_pch <- "https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/pch.txt"
  url_prot_map <- "https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/proteome_mapfile.txt"
  url_tran_map <- "https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/translatome_mapfile.txt"
  url_prot <- "https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/diablo_proteome.txt"
  url_tran <- "https://gitlab.com/tyagilab/sars-cov-2/-/raw/master/data/case_study_1/diablo_translatome.txt"

  urls <- c(url_class, url_pch, url_prot_map, url_tran_map, url_prot, url_tran)
  file_names <- sapply(strsplit(urls, "/"), tail, 1)
  mapply(function(x, y) download.file(x, y), urls, file_names, SIMPLIFY=FALSE)
  if (any(file.exists(file_names)) != TRUE) {stop("Files incorrectly downloaded!")}
  ```
</details>

Load the data and metadata with the following functions. All files must be in the same order!

<details>
  <summary>Click to expand code block</summary>
  Using the pipeline:
  ```{r load_data, eval=FALSE}
  paths <- c("diablo_proteome.txt", "diablo_translatome.txt")
  mappings <- c("proteome_mapfile.txt", "translatome_mapfile.txt")
  classes <- parse_classes("classes_diablo.txt")
  pch <- parse_classes("pch.txt")
  data <- lapply(paths, parse_data, missing_as=NA, rmna=TRUE)
  mapped <- lapply(mappings, parse_mappings)
  # these must be unique
  data_names <- c("proteome", "translatome")
  # design matrix specifying linkage across blocks (for multiomics)
  design <- create_design(data, 0.1)
  ```

  Using the R data object:
  ```{r load_data_obj, eval=TRUE}
  load("RData.RData")
  classes
  lapply(data, dim)
  data_names <- c("proteome", "translatome")
  design <- create_design(data, 0.1)
  pch
  ```

</details>

# Data quality control

Before analysing data further we perform standard checks for common quality issues.

## Accounting for missing values

We discovered a high proportion of missing values within the translatome data. Missing values in data can bias analyses. There are multiple ways to address this. In our case we use a mixture of filtering and imputation.

```{r cor_impute, echo=FALSE, message=FALSE}
cor_imputed_unimputed_ = function(pca_withna, pca_impute, names) {
  # plots a heatmap of correlations: -> df, df, name
  x <- pca_withna
  y <- pca_impute
  z <- names
  print("Plotting correlation between unimputed and imputed components")
  print(ggplot2::ggplot(reshape2::melt(cor(x$variates$X, y$variates$X)),
    ggplot2::aes(Var1, Var2, fill=value)) +
    ggplot2::ggtitle(paste(z, "correlation between imputed and unimputed data")) +
    ggplot2::geom_tile() +
    ggplot2::scale_fill_gradient2(low="blue", high="red", mid="white", midpoint=0,
      limit=c(-1,1), space="Lab", name="Pearson\nCorrelation") +
    ggplot2::theme_minimal()
  )
}
```

<details>
  <summary>Click to expand code block</summary>
  ```{r check_na, eval=TRUE}
  # the data object has already been cleaned, we load the raw data for reference
  unimputed_prot_path <- "diablo_proteome.txt"
  unimputed_prot <- read.table(unimputed_prot_path, sep="\t", header=TRUE, row.names=1)
  unimputed_tran_path <- "diablo_translatome.txt"
  unimputed_tran <- read.table(unimputed_tran_path, sep="\t", header=TRUE, row.names=1)
  unimputed_prot[unimputed_prot == 0] <- NA
  unimputed_tran[unimputed_tran == 0] <- NA
  na_prop_prot <- show_na_prop(unimputed_prot, "Proteome")
  na_prop_tran <- show_na_prop(unimputed_tran, "Translatome")

  # need to drop col where all missing
  unimputed_prot <- remove_na_class(unimputed_prot, classes, missing_as=NA)
  unimputed_tran <- remove_na_class(unimputed_tran, classes, missing_as=NA)
  ```
</details>

We corrected for the missing values in the translatome data (~47% of original data) by a mixture of filtering and imputation. We considered that filtering alone would be too aggressive and imputation alone would be ineffective. Filtering was performed by dropping all features which were not represented across each biological sample group.

<details>
  <summary>Click to expand code block</summary>
  ```{r remove_na, eval=TRUE}
  data <- lapply(data, remove_na_class, classes)
  ```
</details>

This reduced the quantity of missing values to ~17% of the original data. An imputation was performed with the NIPALS algorithm, which is effective on data with < 20% missing values. Note that imputation can take some time, increasing with data size and component count.

<details>
  <summary>Click to expand code block</summary>
  Using the pipeline:
  ```{r impute_na, eval=FALSE}
  # this step is important, some functions use the names internally
  names(data) <- data_names
  data_imp <- impute_missing(data, rep(24, length(data)), outdir="./")

  # only replace the missing values and preserve the original values
  data <- replace_missing(data, data_imp)
  ```

  Using the R data object:
  ```{r impute_na_obj, eval=FALSE}
  lapply(data_imp, dim)
  ```
</details>

> **NOTE**: This step also writes out the imputed, un-replaced data. Since imputation can take some time, this is mainly for convenience. You can load the imputed data directly as input if it meets your requirements.

To test that imputation has not introduced significant technical variation into the data, we observe the correlation between variates of the principal components.

> **NOTE**: All PCAs are centered and scaled.

<details>
  <summary>Click to expand code block</summary>
  ```{r compare_na, eval=TRUE}
  pca_unimputed_prot <- mixOmics::pca(unimputed_prot, ncomp=10)
  pca_unimputed_tran <- mixOmics::pca(unimputed_tran, ncomp=10)
  pca_imputed_prot <- mixOmics::pca(data$proteome, ncomp=10)
  pca_imputed_tran <- mixOmics::pca(data$translatome, ncomp=10)
  cor_imputed_unimputed_(pca_imputed_prot, pca_unimputed_prot, "Proteome")
  cor_imputed_unimputed_(pca_imputed_tran, pca_unimputed_tran, "Translatome")
  ```
  > **NOTE**: Imputation may take some time, go eat lunch

</details>

In both cases, there is a strong correlation between the variates on at least the first 5 principal components corresponding to at least 50% of the variation in the data.

## Accounting for unwanted variation

We observed a "sample effect" in the data in the above PCA, which is likely caused by the longitudinal study design, where sets of cell cultures were resampled over a time series.

<details>
  <summary>Click to expand code block</summary>
  ```{r sample_effect, eval=TRUE}
  data_pca_multilevel <- plot_pca_multilevel(
    data, classes, pch=pch, ncomp=10,
    title=paste("With NA.")
  )
  data_imp <- replace_missing(data, data_imp)
  names(data_imp) <- data_names
  data_pca_multilevel <- plot_pca_multilevel(
    data_imp, classes, pch=pch, ncomp=10,
    title=paste("Imputed.")
  )
  ```
</details>

# Single omics analyses

We next apply the PLSDA (Partial Least Squares Discriminant Analysis) and sPLSDA (sparse variant of PLSDA) method for each block of single-omics data, and as before internally perform a multilevel decomposition to account for the repeated measurements within each cell culture.

## Parameter tuning

To investigate the parameters best suited for the methods, leave-one-out cross validation was performed. The number of components and features selected were tuned internally with a function in the mixOmics package.

<details>
  <summary>Click to expand code block</summary>
  Using the pipeline:
  ```{r tune_splsda, eval=TRUE}
  # this step can take some time
  tuned_splsda <- tune_splsda(
    data_imp, classes, data_names, data.frame(pch), ncomp=4, nrepeat=10,
    logratio="none", test_keepX=c(5,6,7,8,9,10,30), validation="loo", folds=10,
    dist="centroids.dist", cpus=1, progressBar=FALSE
  )
  splsda_keepx <- lapply(tuned_splsda, `[`, "choice.keepX")
  splsda_ncomp <- lapply(tuned_splsda, `[`, "choice.ncomp")

  print("Tuned splsda to use number of components:")
  splsda_ncomp <- lapply(splsda_ncomp, `[`, "ncomp")
  splsda_ncomp <- unlist(splsda_ncomp, recursive=FALSE)
  names(splsda_ncomp) <- data_names
  print(splsda_ncomp)

  print("Tuned the number of variables selected on each component to:")
  print(splsda_keepx)
  splsda_keepx <- unlist(splsda_keepx, recursive=FALSE)
  names(splsda_keepx) <- data_names
  print(splsda_keepx)
  ```

  Using the R data object:
  ```{r tune_splsda_obj, eval=FALSE}
  names(tuned_splsda)

  # keep optimal number of features to keep
  splsda_keepx <- lapply(tuned_splsda, `[`, "choice.keepX")
  splsda_keepx <- unlist(splsda_keepx, recursive=FALSE)
  names(splsda_keepx) <- data_names
  ```

</details>

## Running the analysis

With the tuned parameters, we run sPLSDA (subset of features).

<details>
  <summary>Click to expand code block</summary>
  ```{r splsda_result, eval=TRUE}
  # this step can take some time
  data_splsda <- classify_splsda(
    data=data_imp, classes=classes, pch=pch, title=data_names,
    ncomp=4, keepX=splsda_keepx, contrib="max", outdir="./",
    mappings=NULL, dist="centroids.dist", bg=TRUE
  )
  ```
</details>

We also run PLSDA (all features) for comparison.

<details>
  <summary>Click to expand code block</summary>
  ```{r plsda_result, eval=TRUE}
  # this step can take some time
  data_plsda <- classify_plsda(
    data=data_imp, classes=classes, pch=pch, title=data_names,
    ncomp=4, contrib="max", outdir="./",
    mappings=NULL, dist="centroids.dist", bg=TRUE
  )
  ```
</details>

These automatically generate a large series of plots. Figures are ordered sequentially by each block of omics data in `data_name`, in this case `proteome` followed by `translatome`. Some `txt` files containing feature loadings are also written to the output directory.

## Explanation of output

Detailed technical information on the individual figures types and underlying methods are available at the [mixOmics website](http://mixomics.org/). This walkthrough will explain the plots in context of the biological system under study only. The plots are explained in the order that they appear in this document.

### Scatter plots

Plotting the first few components of the sPLSDA reveals several distinct sample groups, with the main distinction in both omics data blocks as the difference between late stage infected samples with all other samples. This matches the independent observations of the laboratory which originally generated the data. There are multiple secondary distinctions between data groups in both omics data blocks, mostly between groups of timepoints. It is also interesting to note that some sub-groups of data include both infected and uninfected samples.

### Classification error

> **NOTE**: Balanced error rate can be used in cases where classes are imbalanced.

To show accuracy of the method, the classification error rate across multiple components for maximum, centroids and mahalanobis distance are plotted. The centroids distance metric appeared to perform the best in this case, with the lowest error rate after 3 components for proteome and 4 for translatome.

### Feature stability

To assess how stable the feature is across cross-validation, each of the horizontal bars represent a feature. The height of the bar corresponds to stability. We observe three subsets of highly stable features, moderately stable features and less stable features.

### ROC curves

As a supplementary layer of validation, ROC curves showing classification accuracy are available, but we note that these have limited applicability given the specific context of the method. The underlying method already internally specifies the prediction cutoff to achieve maximal sensitivity and specificity.

### Arrow plots

To review agreement between matching data sets, we use an arrow plot. Short arrows suggest a strong similarity, while long arrows indicate dissimilarity. Two sample groups in the proteome data (Virus 6h, Virus 24h) appear to be dissimilar.

### Clustered image maps

To investigate the relationship between samples, these plots can be interpreted like heatmaps. They are coloured by biological class as well as batch information. Individual components can be extracted for custom visualisation if needed.

### Variable loadings

To understand how much a feature contributes to the biological classification, loading weights are shown. Direction of the bar indicates the abundance of that feature in the data (left for less, right for more). Bars are colour coded to biological class. Individual components can be extracted for custom visualisation if needed.

Note that only a subset of these features are visualised. The full list is exported into a tab-separated `txt` file, similar to that from a `limma` differential expression analysis.

### PLSDA

To supplement the sPLSDA, we also compared the performance of PLSDA (a non sparse variant of sPLSDA keeping all features). This showed similarities in patterns across the datasets. The plots are conceptually identical, but several plots are excluded as they are not applicable (feature selection, variable stability).

# Multi omics analyses

Having assessed the major sources of variation and features of interest contributing to biological conditions within the individual blocks of omics data, we can use this information to guide our multi-omics integration.

We applied a latent variable approach to identify a highly correlated multi-omics signature. This analysis is carried out in a conceptually similar way to the previous sPLSDA with similar parameter requirements, except with multiple omics data blocks corrected for longitudinal study effects specified as input. We illustrate the correlation between features across these omics blocks with a circos plot.

## Parameter tuning

To investigate the parameters best suited for the methods, leave-one-out cross validation was performed. Similar to sPLSDA, the number of components and features selected were tuned internally with a function in the mixOmics package.

<details>
  <summary>Click to expand code block</summary>
  Using the pipeline:
  ```{r tune_diablo, eval=FALSE}
  # tune number of components
  tuned_diablo <- tune_diablo_ncomp(data_imp, classes, design, ncomp=8, cpus=1)
  print("Parameters with lowest error rate:")
  tuned_diablo <- tuned_diablo$choice.ncomp$WeightedVote["Overall.BER",]
  diablo_ncomp <- tuned_diablo[which.max(tuned_diablo)]
  print("Number of components:")
  print(diablo_ncomp)

  # tune keepx
  diablo_keepx <- c(5,10,12,14,16,18,20,30)
  diablo_keepx <- tune_diablo_keepx(
    data_imp, classes, diablo_ncomp, design, diablo_keepx, cpus=1,
    dist="mahalanobis.dist", progressBar=FALSE
  )
  print("Diablo keepx:")
  print(diablo_keepx)
  ```

  Using the R object:
  ```{r tune_diablo_obj, eval=TRUE}
  tuned_diablo
  diablo$keepX
  ```
</details>

## Running the analysis

With the tuned parameters, we run multi-block sPLSDA (DIABLO).

<details>
  <summary>Click to expand code block</summary>
  Using the pipeline:
  ```{r run_diablo, eval=FALSE}
  diablo_ncomp <- tuned_diablo[which.max(tuned_diablo)]
  # these values were precomputed, newer versions of code save these values for use
  diablo_keepx <- list(proteome=c(14, 14, 30, 5, 10, 10, 10, 5),
                       translatome=c(10, 5, 20, 5, 5, 5, 10, 5))

  data_imp <- force_unique_blocks(data_imp)

  # run the algorithm
  diablo <- run_diablo(data_imp, classes, diablo_ncomp, design, diablo_keepx)
  ```

  Using the R data object:
  ```{r run_diablo_obj, eval=TRUE}
  diablo
  ```
</details>

## Explanation of output

Many of these plots can be interpreted in conceptually similar ways to that of the single-omic sPLSDA above. However, some extra plots are created to better illustrate correlation between datasets.

> **NOTE**: As usual, the full list of plots and results are available in the git repository.

### Classification error

> **NOTE**: Balanced error rate can be used in cases where classes are imbalanced.

To show accuracy of the method, the classification error rate across multiple components for maximum, centroids and mahalanobis distance are plotted. The centroids distance metric appeared to perform the best in this case, with the lowest error rate after 3 components for proteome and 4 for translatome.

<details>
  <summary>Click to expand code block</summary>
  ```{r perf_diablo}
  # assess performance
  perf_diablo <- mixOmics::perf(
    diablo, validation="loo", nrepeats=10, auc=TRUE, cpus=6, progressBar=TRUE
  )
  plot(perf_diablo)
  ```
</details>

### Feature stability

To assess how stable the feature is across cross-validation, each of the horizontal bars represent a feature. The height of the bar corresponds to stability. We observe three subsets of highly stable features, moderately stable features and less stable features.

<details>
  <summary>Click to expand code block</summary>
  ```{r perf_diablo_stability}
  print("Proteome")
  plot(perf_diablo$features$stable$nrep1$proteome$comp1,
    type="h", main="Comp 1", las=2, ylab="Stability", xlab="Features", xaxt='n'
  )
  print("Translatome")
  plot(perf_diablo$features$stable$nrep1$translatome$comp1,
    type="h", main="Comp 1", las=2, ylab="Stability", xlab="Features", xaxt='n'
  )
  ```
</details>

### Correlation plot

A correlation score is provided per block of omics data. In this case there is just one score as there are two blocks of omics data.

<details>
  <summary>Click to expand code block</summary>
  ```{r diablo}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::plotDiablo(diablo, ncomp=1)
  ```
</details>

### Scatter plots

Plotting the first few components of the multi-block sPLSDA (DIABLO) reveals several distinct sample groups, with the main distinction in both omics data blocks as the difference between late stage infected samples with all other samples. This matches the independent observations of the laboratory which originally generated the data. There are multiple secondary distinctions between data groups in both omics data blocks, mostly between groups of timepoints. It is also interesting to note that some sub-groups of data include both infected and uninfected samples.

<details>
  <summary>Click to expand code block</summary>
  ```{r perf_scatter}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::plotIndiv(
    diablo, ind.names=FALSE, legend=TRUE, title='DIABLO', ellipse=TRUE
  )
  ```
</details>

### ROC curves

As a supplementary layer of validation, ROC curves showing classification accuracy are available, but we note that these have limited applicability given the specific context of the method. The underlying method already internally specifies the prediction cutoff to achieve maximal sensitivity and specificity.

<details>
  <summary>Click to expand code block</summary>
  ```{r perf_auroc}
  # to keep the case study concise we use a custom function to output main plots
  sink("/dev/null")
  mixOmics::auroc(diablo, roc.comp=1)
  sink()
  ```
</details>

### Arrow plots

To review agreement between matching data sets, we use an arrow plot. Short arrows suggest a strong similarity, while long arrows indicate dissimilarity. Two sample groups in the proteome data (Virus 6h, Virus 24h) appear to be dissimilar.

<details>
  <summary>Click to expand code block</summary>
  ```{r perf_arrow}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::plotArrow(diablo, ind.names=FALSE, legend=TRUE, title='DIABLO')
  ```
</details>

### Correlation circle plots

The correlation circle plots highlight the contribution of each variable to each component. A strong correlation between variables is indicated by clusters of points.

<details>
  <summary>Click to expand code block</summary>
  ```{r perf_correlation}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::plotVar(diablo, style='graphics', legend=TRUE, comp=c(1,2),
    title="DIABLO 1/2", var.names=FALSE
  )
  ```
</details>

### Clustered image maps

To investigate the relationship between samples, these plots can be interpreted like heatmaps. They are coloured by biological class as well as batch information. Individual components can be extracted for custom visualisation if needed.

<details>
  <summary>Click to expand code block</summary>
  ```{r cim}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::cimDiablo(diablo, size.legend=0.5, col.names=FALSE)
  ```
</details>

### Variable loadings

To understand how much a feature contributes to the biological classification, loading weights are shown. Direction of the bar indicates the abundance of that feature in the data (left for less, right for more). Bars are colour coded to biological class. Individual components can be extracted for custom visualisation if needed.

Note that only a subset of these features are visualised. The full list is exported into a tab-separated `txt` file, similar to that from a `limma` differential expression analysis.

<details>
  <summary>Click to expand code block</summary>
  ```{r loadings}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::plotLoadings(diablo, contrib="max", comp=1, max.name.length=6,
    method='median', ndisplay=20, size.name=0.6,
    size.legend=0.6, title=paste("DIABLO max loadings")
  )
  ```
</details>

### Circos plot

To visualise correlations between different blocks of omics data, a circos plot is generated. The blue block represents proteome data and the green block represents translatome data. Each point on the circle is a single feature. Lines linking features show correlations between features that pass the user-specified correlation threshold, in this case 0.95. Red lines indicate positive correlation and blue lines negative correlation.

<details>
  <summary>Click to expand code block</summary>
  ```{r circos}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::circosPlot(
    diablo, cutoff=0.95, line=FALSE, size.legend=0.5, size.variables=0.001
  )
  ```
</details>

### Network plot

Similar to the circos plot, a network plot can be generated. It is compatible with cytoscape and can be exported as a `gml` file.

<details>
  <summary>Click to expand code block</summary>
  ```{r network}
  # to keep the case study concise we use a custom function to output main plots
  mixOmics::network(
    diablo, blocks=c(1,2), color.node=c('darkorchid','lightgreen'), cutoff=0.4,
    col.names=FALSE, row.names=FALSE
  )
  ```
</details>

# Output data

Files output by the pipeline include:

- a `pdf` file of all plots generated by the pipeline
- tab-separated `txt` files containing feature contribution weights to each biological class
- tab-separated `txt` file containing correlations between each omics data block

[A `RData` object with all input and output is available in the git repository.](https://gitlab.com/tyagilab/sars-cov-2/-/blob/master/results/case_study_1/RData.RData) This is not included directly in the `multiomics` package because of size constraints, and includes data from two omics datasets.

# Acknowledgements

[Please refer to introduction.](introduction.html)

# References

[Please refer to introduction.](introduction.html)
